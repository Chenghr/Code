{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor and Variable\n",
    "这是 PyTorch 基础的第二课，通过本次课程，你能够学会如何像使用 NumPy 一样使用 PyTorch，了解到 PyTorch 中的基本元素 Tensor 和 Variable 及其操作方式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 把 PyTorch 当做 NumPy 用\n",
    "PyTorch 的官方介绍是一个拥有强力GPU加速的张量和动态构建网络的库，其主要构件是张量，所以我们可以把 PyTorch 当做 NumPy 来用，PyTorch 的很多操作好 NumPy 都是类似的，但是因为其能够在 GPU 上运行，所以有着比 NumPy 快很多倍的速度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 创建一个 numpy ndarray\n",
    "numpy_tensor = np.random.randn(10, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以使用下面两种方式将numpy的ndarray转换到tensor上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pytorch_tensor1 = torch.Tensor(numpy_tensor)\n",
    "pytorch_tensor2 = torch.from_numpy(numpy_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用以上两种方法进行转换的时候，会直接将 NumPy ndarray 的数据类型转换为对应的 PyTorch Tensor 数据类型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同时我们也可以使用下面的方法将 pytorch tensor 转换为 numpy ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 如果 pytorch tensor 在 cpu 上\n",
    "numpy_array = pytorch_tensor1.numpy()\n",
    "\n",
    "# 如果 pytorch tensor 在 gpu 上\n",
    "numpy_array = pytorch_tensor1.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要注意 GPU 上的 Tensor 不能直接转换为 NumPy ndarray，需要使用`.cpu()`先将 GPU 上的 Tensor 转到 CPU 上"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch Tensor 使用 GPU 加速\n",
    "\n",
    "我们可以使用以下两种方式将 Tensor 放到 GPU 上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "CUDA error: invalid device ordinal",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-32da6d5d8d9f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# 第二种方式更简单，推荐使用\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mgpu_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 将 tensor 放到第一个 GPU 上\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mgpu_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 将 tensor 放到第二个 GPU 上\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: invalid device ordinal"
     ]
    }
   ],
   "source": [
    "# 第一种方式是定义 cuda 数据类型\n",
    "dtype = torch.cuda.FloatTensor # 定义默认 GPU 的 数据类型\n",
    "gpu_tensor = torch.randn(10, 20).type(dtype)\n",
    "\n",
    "# 第二种方式更简单，推荐使用\n",
    "gpu_tensor = torch.randn(10, 20).cuda(0) # 将 tensor 放到第一个 GPU 上\n",
    "gpu_tensor = torch.randn(10, 20).cuda(1) # 将 tensor 放到第二个 GPU 上"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用第一种方式将 tensor 放到 GPU 上的时候会将数据类型转换成定义的类型，而是用第二种方式能够直接将 tensor 放到 GPU 上，类型跟之前保持一致\n",
    "\n",
    "推荐在定义 tensor 的时候就明确数据类型，然后直接使用第二种方法将 tensor 放到 GPU 上"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "而将 tensor 放回 CPU 的操作非常简单"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cpu_tensor = gpu_tensor.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们也能够访问到 Tensor 的一些属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([10, 20])\ntorch.Size([10, 20])\n"
    }
   ],
   "source": [
    "# 可以通过下面两种方式得到 tensor 的大小\n",
    "print(pytorch_tensor1.shape)\n",
    "print(pytorch_tensor1.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "# 得到 tensor 的数据类型\n",
    "print(pytorch_tensor1.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# 得到 tensor 的维度\n",
    "print(pytorch_tensor1.dim())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "200\n"
    }
   ],
   "source": [
    "# 得到 tensor 的所有元素个数\n",
    "print(pytorch_tensor1.numel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**小练习**\n",
    "\n",
    "查阅以下[文档](http://pytorch.org/docs/0.3.0/tensors.html)了解 tensor 的数据类型，创建一个 float64、大小是 3 x 2、随机初始化的 tensor，将其转化为 numpy 的 ndarray，输出其数据类型\n",
    "\n",
    "参考输出: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "float64\n"
    }
   ],
   "source": [
    "# 答案\n",
    "x = torch.randn(3, 2)\n",
    "x = x.type(torch.DoubleTensor)\n",
    "x_array = x.numpy()\n",
    "print(x_array.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor的操作\n",
    "Tensor 操作中的 api 和 NumPy 非常相似，如果你熟悉 NumPy 中的操作，那么 tensor 基本是一致的，下面我们来列举其中的一些操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[1., 1.],\n        [1., 1.]])\n"
    }
   ],
   "source": [
    "x = torch.ones(2, 2)# 默认元素为1\n",
    "print(x) # 这是一个float tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.FloatTensor\n"
    }
   ],
   "source": [
    "print(x.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[1, 1],\n        [1, 1]])\n"
    }
   ],
   "source": [
    "# 将其转化为整形\n",
    "x = x.long()\n",
    "# x = x.type(torch.LongTensor)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1  1\n",
      " 1  1\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 再将其转回 float\n",
    "x = x.float()\n",
    "# x = x.type(torch.FloatTensor)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-0.8203 -0.0328  1.8283\n",
      "-0.1734 -0.1873  0.9818\n",
      "-1.8368 -2.2450 -0.4410\n",
      "-0.8005 -2.1132  0.7140\n",
      "[torch.FloatTensor of size 4x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 沿着行取最大值\n",
    "max_value, max_idx = torch.max(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([1, 1])"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "# 每一行的最大值\n",
    "max_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([0, 0])"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "# 每一行最大值的下标\n",
    "max_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.9751\n",
      " 0.6212\n",
      "-4.5228\n",
      "-2.1997\n",
      "[torch.FloatTensor of size 4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 沿着行对 x 求和\n",
    "sum_x = torch.sum(x, dim=1)\n",
    "print(sum_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3])\n",
      "torch.Size([1, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "# 增加维度或者减少维度\n",
    "print(x.shape)\n",
    "x = x.unsqueeze(0) # 在第一维增加\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "x = x.unsqueeze(1) # 在第二维增加\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "x = x.squeeze(0) # 减少第一维\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "x = x.squeeze() # 将 tensor 中所有的一维全部都去掉\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 5])\n",
      "torch.Size([4, 3, 5])\n",
      "torch.Size([5, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, 4, 5)\n",
    "print(x.shape)\n",
    "\n",
    "# 使用permute和transpose进行维度交换\n",
    "x = x.permute(1, 0, 2) # permute 可以重新排列 tensor 的维度\n",
    "print(x.shape)\n",
    "\n",
    "x = x.transpose(0, 2)  # transpose 交换 tensor 中的两个维度\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 5])\n",
      "torch.Size([12, 5])\n",
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "# 使用 view 对 tensor 进行 reshape\n",
    "x = torch.randn(3, 4, 5)\n",
    "print(x.shape)\n",
    "\n",
    "x = x.view(-1, 5) # -1 表示任意的大小，5 表示第二维变成 5\n",
    "print(x.shape)\n",
    "\n",
    "x = x.view(3, 20) # 重新 reshape 成 (3, 20) 的大小\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = torch.randn(3, 4)\n",
    "y = torch.randn(3, 4)\n",
    "\n",
    "# 两个 tensor 求和\n",
    "z = x + y\n",
    "# z = torch.add(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另外，pytorch中大多数的操作都支持 inplace 操作，也就是可以直接对 tensor 进行操作而不需要另外开辟内存空间，方式非常简单，一般都是在操作的符号后面加`_`，比如"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([3, 3])\ntorch.Size([1, 3, 3])\ntorch.Size([3, 1, 3])\n"
    }
   ],
   "source": [
    "x = torch.ones(3, 3)\n",
    "print(x.shape)\n",
    "\n",
    "# unsqueeze 进行 inplace\n",
    "x.unsqueeze_(0)\n",
    "print(x.shape)\n",
    "\n",
    "# transpose 进行 inplace\n",
    "x.transpose_(1, 0)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.]])\ntensor([[2., 2., 2.],\n        [2., 2., 2.],\n        [2., 2., 2.]])\n"
    }
   ],
   "source": [
    "x = torch.ones(3, 3)\n",
    "y = torch.ones(3, 3)\n",
    "print(x)\n",
    "\n",
    "# add 进行 inplace\n",
    "x.add_(y)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**小练习**\n",
    "\n",
    "访问[文档](http://pytorch.org/docs/0.3.0/tensors.html)了解 tensor 更多的 api，实现下面的要求\n",
    "\n",
    "创建一个 float32、4 x 4 的全为1的矩阵，将矩阵正中间 2 x 2 的矩阵，全部修改成2\n",
    "\n",
    "参考输出\n",
    "$$\n",
    "\\left[\n",
    "\\begin{matrix}\n",
    "1 & 1 & 1 & 1 \\\\\n",
    "1 & 2 & 2 & 1 \\\\\n",
    "1 & 2 & 2 & 1 \\\\\n",
    "1 & 1 & 1 & 1\n",
    "\\end{matrix}\n",
    "\\right] \\\\\n",
    "[torch.FloatTensor\\ of\\ size\\ 4x4]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[1., 1., 1., 1.],\n        [1., 2., 2., 1.],\n        [1., 2., 2., 1.],\n        [1., 1., 1., 1.]])\n"
    }
   ],
   "source": [
    "# 答案\n",
    "x = torch.ones(4, 4).float()\n",
    "x[1:3, 1:3] = 2\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable\n",
    "tensor 是 PyTorch 中的完美组件，但是构建神经网络还远远不够，我们需要能够构建计算图的 tensor，这就是 Variable。Variable 是对 tensor 的封装，操作和 tensor 是一样的，但是每个 Variabel都有三个属性，Variable 中的 tensor本身`.data`，对应 tensor 的梯度`.grad`以及这个 Variable 是通过什么方式得到的`.grad_fn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 通过下面这种方式导入 Variable\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_tensor = torch.randn(10, 5) # 从标准正态分布中抽取一组随机数字，构成tensor张量；randn(row,col)\n",
    "y_tensor = torch.randn(10, 5)\n",
    "\n",
    "# 将 tensor 变成 Variable\n",
    "x = Variable(x_tensor, requires_grad=True) # 默认 Variable 是不需要求梯度的，所以我们用这个方式申明需要对其进行求梯度\n",
    "y = Variable(y_tensor, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z = torch.sum(x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor(4.4967)\n<SumBackward0 object at 0x000001C1F41D8B88>\n"
    }
   ],
   "source": [
    "print(z.data)\n",
    "print(z.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面我们打出了 z 中的 tensor 数值，同时通过`grad_fn`知道了其是通过 Sum 这种方式得到的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[1., 1., 1., 1., 1.],\n        [1., 1., 1., 1., 1.],\n        [1., 1., 1., 1., 1.],\n        [1., 1., 1., 1., 1.],\n        [1., 1., 1., 1., 1.],\n        [1., 1., 1., 1., 1.],\n        [1., 1., 1., 1., 1.],\n        [1., 1., 1., 1., 1.],\n        [1., 1., 1., 1., 1.],\n        [1., 1., 1., 1., 1.]])\ntensor([[1., 1., 1., 1., 1.],\n        [1., 1., 1., 1., 1.],\n        [1., 1., 1., 1., 1.],\n        [1., 1., 1., 1., 1.],\n        [1., 1., 1., 1., 1.],\n        [1., 1., 1., 1., 1.],\n        [1., 1., 1., 1., 1.],\n        [1., 1., 1., 1., 1.],\n        [1., 1., 1., 1., 1.],\n        [1., 1., 1., 1., 1.]])\n"
    }
   ],
   "source": [
    "# 求 x 和 y 的梯度\n",
    "z.backward()\n",
    "\n",
    "print(x.grad)\n",
    "print(y.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过`.grad`我们得到了 x 和 y 的梯度，这里我们使用了 PyTorch 提供的自动求导机制，非常方便，下一小节会具体讲自动求导。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**小练习**\n",
    "\n",
    "尝试构建一个函数 $y = x^2 $，然后求 x=2 的导数。\n",
    "\n",
    "参考输出：4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提示：\n",
    "\n",
    "$y = x^2$的图像如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = np.arange(-3, 3.01, 0.1) # numpy.arange([start, ]stop, [step, ]dtype=None), 返回一个一维数组\n",
    "y = x ** 2 # python 中 ** 表示幂运算\n",
    "plt.plot(x, y)\n",
    "plt.plot(2, 4, 'ro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([4.])\n"
    }
   ],
   "source": [
    "# 答案\n",
    "x = Variable(torch.FloatTensor([2]), requires_grad=True)\n",
    "y = x ** 2\n",
    "y.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下一次课程我们将会从导数展开，了解 PyTorch 的自动求导机制"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.7.9 64-bit ('py37': conda)",
   "display_name": "Python 3.7.9 64-bit ('py37': conda)",
   "metadata": {
    "interpreter": {
     "hash": "1076d75ba6481e59188a280dd8fe8a3edf2f577c1db448ea9bd8e6209e7d4232"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}